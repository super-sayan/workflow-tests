name: Dependency Track SCA
on:
  workflow_dispatch:

env:
  DEPENDENCY_TRACK_API_KEY: ${{ secrets.DEPENDENCYTRACK_APIKEY }} # API Key for using Dependecy Track API
  DEPENDENCY_TRACK_BASE_URL: ${{ secrets.API_URL }} # URL of Dependency Track API server
  DEPENDENCY_TRACK_SHORT_URL: ${{ secrets.API_SURL }}
  PROJECT_NAME: ${{ github.repository }}
  EPSS_WEIGHT: 1
  CVSS_WEIGHT: 1

jobs:
  code_analysis:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
    steps:
      # Define repo for output of results.
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4.1.0
      
      - name: Setup Python
        uses: actions/setup-python@v5.3.0
        
      - name: Find Dependency Files
        id: locate-dependencies
        run: |
          echo "Searching for JavaScript/TypeScript dependency files..."
          find . -name "package.json" -exec dirname {} \; >> dependency_dirs.txt
          echo "Searching for Python dependency files..."
          find . -name "requirements.txt" -exec dirname {} \; >> dependency_dirs.txt
          # Export as a reusable list
          DEPENDENCY_DIRS=$(cat dependency_dirs.txt | tr '\n' ' ')
          echo "Found directories: $DEPENDENCY_DIRS"
          echo "DEPENDENCY_DIRS=$DEPENDENCY_DIRS" >> $GITHUB_ENV
       
      - name: Install Dependencies
        run: |
          for dir in ./server ./client; do
            echo "Installing dependencies in $dir"
            cd "$dir" || exit
            if [ -f "package.json" ]; then
              echo "Installing Node.js dependencies..."
              npm install
            fi  # Close the if block for package.json
  
            if [ -f "requirements.txt" ]; then
              echo "Installing Python dependencies..."
              python -m pip install --upgrade pip
              pip install -r requirements.txt
            else
              echo "No requirements.txt found, skipping..."
            fi  # Close the if block for requirements.txt

            cd - || exit
          done             
      
      # Running Dependecy Check to define unused dependencies and create txt of unused deps.
      - name: Run Unused Dependency Check
        run: |
          path=$PWD
          echo "Unused Dependencies:" > unused_dependencies.txt
          for dir in ${{ env.DEPENDENCY_DIRS }}; do
            echo "Checking for unused dependencies in $dir..."
            cd "$dir" || exit
            if [ -f "package.json" ]; then
              echo "Running depcheck for Node.js..."
              output=$(npx depcheck || true)
              
              # Parse and annotate unused dependencies.
              if echo "$output" | grep -q "Unused dependencies"; then
                echo "$output" | sed -n '/Unused dependencies/,$p' | while IFS= read -r line; do
                  if [[ $line == "*"* ]]; then
                    dep=$(echo "$line" | sed -E 's/\* //; s/:.*$//')
                    cd $path
                    echo "$dep" >> unused_dependencies.txt
                  fi
                done
              fi

              # Parse and annotate unused devDependencies.
              if echo "$output" | grep -q "Unused devDependencies"; then
                echo "$output" | sed -n '/Unused devDependencies/,$p' | while IFS= read -r line; do
                  if [[ $line == "*"* ]]; then
                    dep=$(echo "$line" | sed -E 's/\* //; s/:.*$//')
                    cd $path
                    echo "$dep" >> unused_dependencies.txt
                  fi
                done
              fi
            else
              pip install deptry
              echo "Running deptry for Python..."
              deptry_output=$(deptry . 2>&1 || true)
              cd $path
              echo "$deptry_output" > deptry_output
              grep "DEP002" deptry_output | awk -F"'" '{print $2}' >> unused_dependencies.txt
            fi
          done

          cat unused_dependencies.txt
      
      # Generating SBOM using Trivy.
      - name: Setup Trivy Action
        uses: aquasecurity/trivy-action@0.29.0
        with:
          scan-type: 'fs'
          format: 'cyclonedx'
          output: 'sbom.json'
           
      # An official Dependecy Track action for SBOM upload, doesn't work good with full URL of Dep Track Server.
      - name: Upload SBOM to Dependency Track
        uses: DependencyTrack/gh-upload-sbom@v3
        with:
          serverHostname: ${{ env.DEPENDENCY_TRACK_SHORT_URL }}
          apiKey: ${{ env.DEPENDENCY_TRACK_API_KEY }}
          projectName: ${{ env.PROJECT_NAME }}
          projectVersion: '1.0.0'
          bomFilename: "./sbom.json"
          autoCreate: true
          
      - name: Wait for SBOM Analysis
        run: |
          sleep 30
        
      # Getting uuid of Project, that we have created on the previous step.
      - name: Fetch Project ID
        id: fetch-project
        run: |
          project_id=$(curl -s -H "X-Api-Key: ${{ env.DEPENDENCY_TRACK_API_KEY }}" \
          "${{ env.DEPENDENCY_TRACK_BASE_URL }}/api/v1/project" | jq -r '.[] | select(.name == "${{ env.PROJECT_NAME }}") | .uuid')
          echo "Project ID: $project_id"
          echo "project_id=$project_id" >> $GITHUB_ENV

      # Getting analysis results from project using it's uuid in sarif/json format.
      - name: Fetch EPSS Data
        id: fetch-epss
        run: |
          curl -s -H "X-Api-Key: ${{ env.DEPENDENCY_TRACK_API_KEY }}" \
          "${{ env.DEPENDENCY_TRACK_BASE_URL }}/api/v1/finding/project/$project_id" \
          -o epss.json  
          echo "EPSS data fetched successfully." 
        # -H "Accept: application/sarif+json" \

      - name: Gather Dependencies from package.json and requirements.txt Files
        run: |
          python - <<EOF
          import json
          import os
          import re

          # Load package.json and requirements.txt files and collect dependencies
          package_dirs = "${{ env.DEPENDENCY_DIRS }}".split()
          dependency_map = {}

          for dir_path in package_dirs:
              # Handle package.json
              package_json_path = os.path.join(dir_path, "package.json")
              try:
                  with open(package_json_path, "r") as f:
                      package_data = json.load(f)
                      dependencies = package_data.get("dependencies", {})
                      for dep, version in dependencies.items():
                          dependency_map[dep] = {
                              "version": version,
                              "file": package_json_path.replace("./", "")
                          }
              except (json.JSONDecodeError, FileNotFoundError):
                  print(f"Failed to parse {package_json_path}")

              # Handle requirements.txt
              requirements_txt_path = os.path.join(dir_path, "requirements.txt")
              try:
                  with open(requirements_txt_path, "r") as f:
                      for line in f:
                          # Match dependencies of the form: package==version or package>=version
                          match = re.match(r"^([a-zA-Z0-9_\-]+)([=><]+[0-9\.]+)?", line.strip())
                          if match:
                              dep = match.group(1)
                              version = match.group(2) if match.group(2) else "unknown"
                              dependency_map[dep] = {
                                  "version": version,
                                  "file": requirements_txt_path.replace("./", "")
                              }
              except FileNotFoundError:
                  print(f"No requirements.txt found in {dir_path}")

          # Save consolidated dependencies for later use
          with open("dependency_locations.json", "w") as out_file:
              json.dump(dependency_map, out_file, indent=2)

          print("Dependency locations saved to dependency_locations.json")
          EOF

      - name: Convert JSON to SARIF
        run: |
          python - <<EOF
          import json
          import re
          import os
          def find_dep_location(dep_name):
              """
                Search for a dependency in package-lock.json files.

              Args:
                    dep_name (str): The name of the dependency to search for.

              Returns:
                  str: Path to the package-lock.json file containing the dependency, or "unknown".
              """
              # Convert dep_name from the format "pkg:npm/name@version" to "name-version"
              if "npm/" in dep_name and "@" in dep_name:
                  search_name = dep_name.split("npm/")[1].replace("@", "-")
              else:
                  return "unknown"
              
              # Iterate through directories containing package-lock.json
              package_dirs = "${{ env.DEPENDENCY_DIRS }}".split()
              for dir_path in package_dirs:
                  lockfile_path = os.path.join(dir_path, "package-lock.json")
                  try:
                      with open(lockfile_path, "r") as lockfile:
                          lock_data = json.load(lockfile)
                          # Traverse dependencies in the package-lock.json file
                          for dep, details in lock_data.get("packages", {}).items():
                              resolved = details.get("resolved", "")
                              if search_name in resolved:
                                  return lockfile_path.replace("./", "")
                  except (json.JSONDecodeError, FileNotFoundError):
                      print(f"Failed to parse {lockfile_path}")
              return "unknown-lock"
              
          def epss_score_to_severity(epss_score, cvss_score):
              """
              This fucntion calculates a severity of cves based on their EPSS and CVSS scores.
              """
              normalized_epss = 1
              if epss_score > 0.6:
                  normalized_epss = 5
              elif epss_score > 0.3:
                  normalized_epss = 4
              elif epss_score > 0.1:
                  normalized_epss = 3
              elif epss_score >= 0.01:
                  normalized_epss = 2
              normalized_cvss = 1
              if cvss_score >= 9.0:
                  normalized_cvss = 5
              elif cvss_score >= 7.0:
                  normalized_cvss = 4
              elif cvss_score >= 4.0:
                  normalized_cvss = 3
              elif cvss_score >= 0.1:
                  normalized_cvss = 2
              severity = round((${{ env.CVSS_WEIGHT }} * normalized_cvss + ${{ env.EPSS_WEIGHT }} * normalized_epss) / (${{ env.CVSS_WEIGHT }} + ${{ env.EPSS_WEIGHT }}))
              if severity == 1:
                  return "0"
              elif severity == 2:
                  return "2"
              elif severity == 3:
                  return "5"
              elif severity == 4:
                  return "8"
              else:
                  return "10"
              return str(severity*2)
                  
          def find_dependency_line(file_path, dependency_name):
              """
              Find the line number of the dependency in a file, supporting both JSON and plain text formats.
              """
              try:
                  with open(file_path, "r") as file:
                      lines = file.readlines()
            
                      # Detect file format based on extension
                      if file_path.endswith(('.json', '.lock')):  # JSON-based files
                          for i, line in enumerate(lines, start=1):
                              # Match the dependency name as a JSON key
                              if re.search(f'"{re.escape(dependency_name)}"', line):
                                  return i
                      elif file_path.endswith('.txt'):  # Plain text files like requirements.txt
                          for i, line in enumerate(lines, start=1):
                              # Match the dependency name in the line (e.g., Flask==2.2.3 or Flask>=2.2.0)
                              if re.match(f'^{re.escape(dependency_name)}([=><!].*)?$', line.strip(), re.IGNORECASE):
                                  return i
              except FileNotFoundError:
                  print(f"File not found: {file_path}")
              except json.JSONDecodeError:
                  print(f"Failed to parse JSON in file: {file_path}")
              return 1  # Default to line 1 if not found
          
          def transform_epss_to_sarif(input_json_path, output_sarif_path):
              """
              Transform EPSS JSON into SARIF format.
          
              Args:
                  input_json_path (str): Path to the input EPSS JSON file.
                  output_sarif_path (str): Path to save the transformed SARIF file.
              """
              # Load the EPSS JSON file
              with open(input_json_path, "r") as file:
                  epss_data = json.load(file)
              # Load dependency locations
              with open("dependency_locations.json", "r") as dep_file:
                  dependency_locations = json.load(dep_file)
                  
              # Initialize SARIF structure
              sarif = {
                  "version": "2.1.0",
                  "\$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/main/sarif-2.1/schema/sarif-schema-2.1.0.json",
                  "runs": [
                      {
                          "tool": {
                              "driver": {
                                  "fullName": "OWASP Dependency Track",
                                  "informationUri": "https://dependency-track.org/",
                                  "name": "Dependency-Track",
                                  "rules": []
                              }
                          },
                          "results": []
                      }
                  ]
              }
          
              rules = []
              results = []
              
              unused_deps = ""
              with open("unused_dependencies.txt", "r") as file:
                  unused_deps = file.read()
                  
              for entry in epss_data:
                  component = entry["component"]
                  vulnerability = entry["vulnerability"]
                  dep_name = component["name"]
                  if dep_name in dependency_locations:
                      location_info = dependency_locations[dep_name]
                      file_path = location_info.get("file", "unknown")
                  else:
                      file_path = find_dep_location(component["purl"])
                  epss_score = vulnerability.get("epssScore", 0)
                  cvss_score = vulnerability.get("cvssV3BaseScore", 0)
                  severity = "0"
                  usage = "unused dependency"
                  if dep_name not in unused_deps: 
                      severity = epss_score_to_severity(epss_score, cvss_score)
                      usage = "dependency in use"
                  # Add rule if not already added
                  rule = {
                      "id": vulnerability["vulnId"],
                      "name": vulnerability.get("cweName", "Unknown CWE"),
                      "fullDescription": {
                          "text": vulnerability["description"]
                      },
                      "defaultConfiguration": {
                          "level": "note"
                      },
                      "helpUri": f"https://nvd.nist.gov/vuln/detail/{vulnerability['vulnId']}",
                      "help": {
                          "text": (
                              f"Vulnerability {vulnerability['vulnId']}\n"
                              f"Package: {component['purl']}\n"
                              f"cvssScore: {cvss_score}\n"
                              f"epssScore: {epss_score}\n"
                              f"Link: [CVE-{vulnerability['vulnId']}](https://nvd.nist.gov/vuln/detail/{vulnerability['vulnId']})\n"
                              f"{vulnerability['description']}"
                          ),
                          "markdown": (
                              f"**Vulnerability {vulnerability['vulnId']}**\n"
                              f"| Package | cvssScore | epssScore | Link |\n"
                              f"| --- | --- | --- | --- |\n"
                              f"|{component['purl']}|{cvss_score}|{epss_score}|"
                              f"[CVE-{vulnerability['vulnId']}](https://nvd.nist.gov/vuln/detail/{vulnerability['vulnId']})|\n\n"
                              f"{vulnerability['description']}"
                          )
                      },
                      "properties": {
                          "security-severity": severity,
                          "tags": [
                              "vulnerability",
                              "security",
                              usage
                          ]
                      }
                  }
                  if rule not in rules:
                      rules.append(rule)
          
                  # Add result
                  result = {
                      "ruleId": vulnerability["vulnId"],
                      "level": "note",
                      "message": {
                          "text": (
                              f"Vulnerability {vulnerability['vulnId']}\n"
                              f"Package: {component['purl']}\n"
                              f"cvssScore: {cvss_score}\n"
                              f"epssScore: {epss_score}\n"
                              f"Link: [CVE-{vulnerability['vulnId']}](https://nvd.nist.gov/vuln/detail/{vulnerability['vulnId']})"
                          )
                      },
                      "locations": [
                          {
                              "physicalLocation": {
                                  "artifactLocation": {
                                      "uri": file_path,
                                      "uriBaseId": "ROOTPATH"
                                  },
                                  "region": {
                                      "startLine": find_dependency_line(file_path, dep_name),
                                      "startColumn": 1,
                                      "endLine": find_dependency_line(file_path, dep_name),
                                      "endColumn": 1
                                  }
                              },
                              "message": {
                                  "text": f"package.json: {component['purl']}"
                              }
                          }
                      ]
                  }
                  results.append(result)
          
              # Assign rules and results to SARIF
              sarif["runs"][0]["tool"]["driver"]["rules"] = rules
              sarif["runs"][0]["results"] = results
          
              # Save the SARIF file
              with open(output_sarif_path, "w") as file:
                  json.dump(sarif, file, indent=2)
          
              print(f"SARIF file saved to {output_sarif_path}")
          transform_epss_to_sarif("epss.json", "epss.sarif")          
          EOF

          
      # Official Github Action for uploading results in sarif format to Github Security tab.
      - name: Upload EPSS Data as SARIF
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: epss.sarif
          category: dependency-track
     #     token: ${{ secrets.PAT }}

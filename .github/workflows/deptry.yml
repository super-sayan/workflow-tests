name: Remove Unused Deps
on:
  workflow_dispatch:

env:
  DEPENDENCY_TRACK_API_KEY: ${{ secrets.DEPENDENCYTRACK_APIKEY }} # API Key for using Dependecy Track API
  DEPENDENCY_TRACK_BASE_URL: ${{ secrets.API_URL }} # URL of Dependency Track API server
  DEPENDENCY_TRACK_SHORT_URL: ${{ secrets.API_SURL }}
  PROJECT_NAME: ${{ github.repository }}

jobs:
  code_analysis:
    runs-on: ubuntu-latest
    permissions:
      security-events: write
    steps:
      # Define repo for output of results.
      - name: Checkout Code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4.1.0
      
      - name: Setup Python
        uses: actions/setup-python@v5.3.0
        
      - name: Find Dependency Files
        id: locate-dependencies
        run: |
          echo "Searching for JavaScript/TypeScript dependency files..."
          find . -name "package.json" -exec dirname {} \; >> dependency_dirs.txt
          echo "Searching for Python dependency files..."
          find . -name "requirements.txt" -exec dirname {} \; >> dependency_dirs.txt
          # Export as a reusable list
          DEPENDENCY_DIRS=$(cat dependency_dirs.txt | tr '\n' ' ')
          echo "Found directories: $DEPENDENCY_DIRS"
          echo "DEPENDENCY_DIRS=$DEPENDENCY_DIRS" >> $GITHUB_ENV
      
      - name: Install Dependencies
        run: |
          for dir in ./server ./client; do
            echo "Installing dependencies in $dir"
            cd "$dir" || exit
            if [ -f "package.json" ]; then
              echo "Installing Node.js dependencies..."
              npm install
            fi  # Close the if block for package.json
  
            if [ -f "requirements.txt" ]; then
              echo "Installing Python dependencies..."
              python -m pip install --upgrade pip
              pip install -r requirements.txt
            else
              echo "No requirements.txt found, skipping..."
            fi  # Close the if block for requirements.txt

            cd - || exit
          done      
      
      # Running Dependecy Check to define unused dependencies and create txt of unused deps.
      - name: Run Unused Dependency Check
        run: |
          echo "Unused Dependencies:" > unused_dependencies.txt
          for dir in ${{ env.DEPENDENCY_DIRS }}; do
            echo "Checking for unused dependencies in $dir..."
            cd "$dir" || exit
            if [ -f "package.json" ]; then
              echo "Running depcheck for Node.js..."
              output=$(npx depcheck || true)

              # Parse and annotate unused dependencies.
              if echo "$output" | grep -q "Unused dependencies"; then
                echo "$output" | sed -n '/Unused dependencies/,$p' | while IFS= read -r line; do
                  if [[ $line == "*"* ]]; then
                    dep=$(echo "$line" | sed -E 's/\* //; s/:.*$//')
                    echo "$dep" >> unused_dependencies.txt
                  fi
                done
              fi

              # Parse and annotate unused devDependencies.
              if echo "$output" | grep -q "Unused devDependencies"; then
                echo "$output" | sed -n '/Unused devDependencies/,$p' | while IFS= read -r line; do
                  if [[ $line == "*"* ]]; then
                    dep=$(echo "$line" | sed -E 's/\* //; s/:.*$//')
                    echo "$dep" >> unused_dependencies.txt
                  fi
                done
              fi
            else
              pip install deptry
              echo "Running deptry for Python..."
              deptry_output=$(deptry . 2>&1 || true)
              echo "Deptry output:"
              echo "$deptry_output"
              echo "$deptry_output" > deptry_output
              grep "DEP002" deptry_output | awk -F"'" '{print $2}' >> unused_dependencies.txt
            fi
          done

          cat unused_dependencies.txt
      
      # Installing Trivy for SBOM generation.
      - name: Install Trivy for SBOM Generation
        run: |
          curl -sSL https://github.com/aquasecurity/trivy/releases/download/v0.58.0/trivy_0.58.0_Linux-64bit.tar.gz | sudo tar xz -C /usr/local/bin
      
      # Generating SBOM using Trivy.
      - name: Generate SBOM using Trivy
        run: |
          trivy fs --format cyclonedx --output sbom.json .
      
      - name: Upload Test results
        uses: actions/upload-artifact@master
        with:
           name: Unfiltered Deps
           path: sbom.json
           
      # Remove unused dependecies from generated SBOM.
      - name: Remove Unused Dependencies from SBOM
        run: |
          echo "Removing unused dependencies from SBOM"
    
          # Read unused dependencies into a list.
          unused_deps=$(cat unused_dependencies.txt)
    
          # Convert the list into a JSON array of objects with `group` and `name`.
          unused_json=$(echo "$unused_deps" | jq -R -s '
            split("\n") | 
            map(select(length > 0)) |
            map(if test("^@") then 
                  {group: (split("/")[0]), name: (split("/")[1])} 
                else 
                  {group: null, name: .} 
                end)
          ')

          # Filter components, matching against both `group` and `name`.
          jq --argjson unused "$unused_json" '
            .components |= map(select(
              .name as $name | 
              .group as $group |
              ($unused | map(.name == $name and .group == $group) | any) | not
            ))
          ' sbom.json > filtered_sbom.json
      
      - name: Upload Test results
        uses: actions/upload-artifact@master
        with:
           name: Filtered Deps
           path: filtered_sbom.json
      
      - name: Gather Dependencies from package.json and requirements.txt Files
        run: |
          python - <<EOF
          import json
          import os
          import re
          
          # Load package.json and requirements.txt files and collect dependencies
          package_dirs = "./client ./server".split()
          dependency_map = {}
          
          for dir_path in package_dirs:
              # Handle package.json
              package_json_path = os.path.join(dir_path, "package.json")
              if os.path.exists(package_json_path):
                  try:
                      with open(package_json_path, "r", encoding="utf-8") as f:
                          package_data = json.load(f)
                          dependencies = package_data.get("dependencies", {})
                          for dep, version in dependencies.items():
                              if dep not in dependency_map:
                                  dependency_map[dep] = {
                                      "version": version,
                                      "files": [package_json_path.replace("./", "")]
                                  }
                              else:
                                  # Append the file and avoid duplicates
                                  dependency_map[dep]["files"].append(package_json_path.replace("./", ""))
                                  dependency_map[dep]["files"] = list(set(dependency_map[dep]["files"]))
                                  # Optionally, update the version if it's more specific
                                  if version != dependency_map[dep]["version"]:
                                      dependency_map[dep]["version"] = version
                  except json.JSONDecodeError:
                      print(f"Failed to parse JSON in {package_json_path}")
                  except UnicodeDecodeError:
                      print(f"Encoding error while reading {package_json_path}")
              else:
                  print(f"No package.json found in {dir_path}")
          
              # Handle requirements.txt
              requirements_txt_path = os.path.join(dir_path, "requirements.txt")
              if os.path.exists(requirements_txt_path):
                  try:
                      with open(requirements_txt_path, "r", encoding="utf-8") as f:
                          for line in f:
                              # Match dependencies of the form: package==version or package>=version
                              match = re.match(r"^([a-zA-Z0-9_\-]+)([=><]+[0-9\.]+)?", line.strip())
                              if match:
                                  dep = match.group(1)
                                  version = match.group(2) if match.group(2) else "unknown"
                                  if dep not in dependency_map:
                                      dependency_map[dep] = {
                                          "version": version,
                                          "files": [requirements_txt_path.replace("./", "")]
                                      }
                                  else:
                                      # Append the file and avoid duplicates
                                      dependency_map[dep]["files"].append(requirements_txt_path.replace("./", ""))
                                      dependency_map[dep]["files"] = list(set(dependency_map[dep]["files"]))
                                      # Optionally, update the version if it's more specific
                                      if version != "unknown" and version != dependency_map[dep]["version"]:
                                          dependency_map[dep]["version"] = version
                  except UnicodeDecodeError:
                      print(f"Encoding error while reading {requirements_txt_path}")
              else:
                  print(f"No requirements.txt found in {dir_path}")
          
          # Save consolidated dependencies for later use
          with open("dependency_locations.json", "w", encoding="utf-8") as out_file:
              json.dump(dependency_map, out_file, indent=2)
          
          print("Dependency locations saved to dependency_locations.json")
          EOF

      - name: Upload Test results
        uses: actions/upload-artifact@master
        with:
           name: dep locs
           path: dependency_locations.json
